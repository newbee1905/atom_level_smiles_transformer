block_size: 1024
n_encoder_layer: 12
n_decoder_layer: 12
n_head: 12
d_model: 768
dropout: 0.1
use_submersion: false
submersion_pooling_method: "mean"
immersion_activation: "silu"
use_kv_cache: false
use_gate: true
use_qk_norm: true
ffn_multiplier: 2.6666666666666665
rope_theta: 10000.0
layer_scale_init: 0.0001
