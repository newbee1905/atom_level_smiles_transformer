import argparse
import subprocess
import sys
from pathlib import Path

SLURM_SCRIPT_TEMPLATE = """#!/bin/bash
#
# This script is auto-generated by train_slurm.py. Do not edit manually.
#
#SBATCH --qos=xbatch
#SBATCH --gpus={gpu_type}:{num_gpus}
#SBATCH --nodes={num_nodes}
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=10
#SBATCH --time={time}
#SBATCH --mem={mem}
#SBATCH --output=logs/{job_name}_%j.out
#SBATCH --error=logs/{job_name}_%j.err
#SBATCH --job-name={job_name}
#SBATCH --mail-type=ALL
#SBATCH --mail-user={mail_user}

set -euo pipefail

# --- Environment Setup ---
echo "Loading modules..."

# Note: This line is cluster-specific. Adjust if necessary.
module load NVHPC/24.9-CUDA-12.6.0
module load Anaconda3/2024.02

eval "$(conda shell.bash hook)"

set +u
conda activate rust_build_env
set -u

export LIBCLANG_PATH="$CONDA_PREFIX/lib"
export LD_LIBRARY_PATH="$CONDA_PREFIX/lib:$LD_LIBRARY_PATH"

echo "Build Env Ready."
echo "Rustc path: $(which rustc)"
echo "Clang path: $(which clang)"
echo "Libclang path: $LIBCLANG_PATH"

unset CONDA_PREFIX

echo "Activating virtual environment..."
source .venv/bin/activate

if [ -z "${{PYTHONPATH:-}}" ]; then
	export PYTHONPATH=.
else
	export PYTHONPATH="$PYTHONPATH:."
fi

# --- DDP Setup ---
export OMP_NUM_THREADS=1
export MASTER_ADDR=$(scontrol show hostname $SLURM_JOB_NODELIST | head -n 1)
export MASTER_PORT=$(shuf -i 29500-65535 -n 1)
GPUS_PER_NODE={num_gpus}

# --- Job Execution ---
echo "--- Job Info ---"
echo "Starting SLURM job $SLURM_JOB_ID on $(hostname)"
echo "Model Config: {model_config}"
echo "Master Node: $MASTER_ADDR, Port: $MASTER_PORT"
echo "GPUs per node: $GPUS_PER_NODE"
echo "Nodes: {num_nodes}"
echo "Hydra args: {hydra_args_str}"
echo "----------------"
nvidia-smi

pkill -u $(whoami) -f python || true
sleep 2

echo "Debug: MASTER_ADDR=$MASTER_ADDR MASTER_PORT=$MASTER_PORT"

srun torchrun \
	--nproc_per_node=$GPUS_PER_NODE \
	--nnodes=$SLURM_NNODES \
	--rdzv_id=$SLURM_JOB_ID \
	--rdzv_backend=c10d \
	--rdzv_endpoint=$MASTER_ADDR:$MASTER_PORT \
	main.py model={model_config} {hydra_args_str}

echo "SLURM job $SLURM_JOB_ID finished."
"""


def main():
	"""Parses arguments, generates a SLURM script, and submits it."""
	parser = argparse.ArgumentParser(
		description="Generate and submit a SLURM job for training Chemformer.",
		formatter_class=argparse.RawTextHelpFormatter,
		usage="python %(prog)s --model_config <config> [options] -- [hydra_options]",
	)

	# SLURM arguments
	slurm_group = parser.add_argument_group("SLURM Configuration")
	slurm_group.add_argument(
		"--model_config",
		type=str,
		required=True,
		help="Name of the model config in config/model (e.g., 'laptop', 'original').",
	)
	slurm_group.add_argument("--num_gpus", type=int, default=4, help="Number of GPUs to request per node.")
	slurm_group.add_argument(
		"--gpu_type", type=str, default="v100", help="Type of GPU to request (e.g., 'l40s', 'v100')."
	)
	slurm_group.add_argument("--num_nodes", type=int, default=1, help="Number of nodes to request.")
	slurm_group.add_argument("--time", type=str, default="3-00:00:00", help="Job time limit (e.g., '1-00:00:00').")
	slurm_group.add_argument("--mem", type=str, default="32G", help="Memory per node (e.g., '64G').")
	slurm_group.add_argument("--job_name", type=str, default=None, help="Job name. Defaults to 'train-<model_config>'.")
	slurm_group.add_argument(
		"--mail_user", type=str, default="s221056384@deakin.edu.au", help="Email for notifications."
	)
	slurm_group.add_argument("--run_tag", type=str, default=None, help="Optional custom tag for the run name and logs.")

	# Task arguments
	task_group = parser.add_argument_group("Task Configuration")
	task_group.add_argument(
		"--pretrain_model_path",
		type=str,
		default=None,
		help="Path to a pretrained model checkpoint to load for fine-tuning. Overrides `task.pretrain_checkpoint`.",
	)

	# Script behavior arguments
	action_group = parser.add_argument_group("Script Actions")
	action_group.add_argument(
		"--dry_run",
		action="store_true",
		help="Print the generated script to stdout instead of submitting it to sbatch.",
	)

	# All arguments after '--' will be treated as hydra arguments
	args, hydra_args = parser.parse_known_args()
	if hydra_args and hydra_args[0] == "--":
		hydra_args = hydra_args[1:]

	# Generate a more descriptive job name
	task_name = "task"
	for arg in hydra_args:
		if arg.startswith("task="):
			task_name = arg.split("=")[-1]
			break

	if args.job_name is None:
		base_name = f"{task_name}-{args.model_config}"
		if args.run_tag:
			args.job_name = f"{base_name}-{args.run_tag}"
		else:
			args.job_name = base_name

	# Add pretrain_model_path to hydra args if provided
	if args.pretrain_model_path:
		hydra_args.append(f"task.pretrain_checkpoint='{args.pretrain_model_path}'")

	# Add run_tag to hydra args if provided
	if args.run_tag:
		hydra_args.append(f"run_tag='{args.run_tag}'")

	hydra_args_str = " ".join(hydra_args)
	Path("logs").mkdir(exist_ok=True)

	slurm_script_content = SLURM_SCRIPT_TEMPLATE.format(
		model_config=args.model_config,
		num_gpus=args.num_gpus,
		gpu_type=args.gpu_type,
		num_nodes=args.num_nodes,
		time=args.time,
		mem=args.mem,
		job_name=args.job_name,
		mail_user=args.mail_user,
		hydra_args_str=hydra_args_str,
	)

	if args.dry_run:
		print("--- Generated SLURM Script (Dry Run) ---")
		print(slurm_script_content)
		return

	print(f"Submitting job '{args.job_name}' to SLURM...")
	try:
		# Use subprocess.run to pipe the script content to sbatch
		process = subprocess.run(["sbatch"], input=slurm_script_content, text=True, capture_output=True, check=True)
		print("Job submitted successfully!")
		print(process.stdout.strip())
		if process.stderr:
			print("sbatch stderr:", process.stderr, file=sys.stderr)

	except FileNotFoundError:
		print("Error: 'sbatch' command not found. Are you on a SLURM login node?", file=sys.stderr)
		sys.exit(1)
	except subprocess.CalledProcessError as e:
		print(f"Error submitting job to SLURM (exit code {e.returncode}):", file=sys.stderr)
		print(e.stdout, file=sys.stdout)
		print(e.stderr, file=sys.stderr)
		sys.exit(1)


if __name__ == "__main__":
	main()
